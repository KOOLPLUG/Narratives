# -*- coding: utf-8 -*-
"""NarrAItives.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1kZ8LyTHhebkXHORACgKKPOol0Sd-Rl1F
"""

# Commented out IPython magic to ensure Python compatibility.
# %pip install streamlit torch newspaper3k beautifulsoup4 lxml requests lxml_html_clean

# Commented out IPython magic to ensure Python compatibility.
# %%writefile app.py
# 
# import streamlit as st
# import os
# from newspaper import Article
# import matplotlib.pyplot as plt
# import pandas as pd
# from transformers import pipeline
# 
# # Load Hugging Face zero-shot classification model
# @st.cache_resource
# def load_model():
#     return pipeline("zero-shot-classification", model="facebook/bart-large-mnli")
# 
# classifier = load_model()
# 
# # Function to fetch article text (remains the same)
# def fetch_article_text(url):
#     """Fetches article and returns the text."""
#     try:
#         article = Article(url)
#         article.download()
#         article.parse()
#         text = article.text.strip()
#         return {"text": text}
#     except Exception as e:
#         return {"error": f"Error fetching article: {e}"}
# 
# def classify_text_zero_shot(text, candidate_labels):
#     """Classifies text using zero-shot classification."""
#     try:
#         result = classifier(text, candidate_labels)
#         return result
#     except Exception as e:
#         return {"error": f"Error during classification: {e}"}
# 
# def main():
#     st.sidebar.title("Navigation")
#     page = st.sidebar.radio("Go to", ["Home", "Article Text Viewer", "Popular Rhetoric Timeline", "About"])
# 
#     st.title("NarrAItives")
# 
#     if page == "Home":
#         home_page()
#     elif page == "Article Text Viewer":
#         article_text_viewer_page()
#     elif page == "Popular Rhetoric Timeline":
#         popular_rhetoric_timeline_page()
#     elif page == "About":
#         about_page()
# 
# def home_page():
#     st.header("uncover the patterns shaping your world")
#     st.write("Welcome to NarrAItives! This application helps you analyze news articles.")
#     st.write("Now you can use the 'Article Text Viewer' to fetch article text and perform zero-shot classification.")
#     st.write("Use the navigation on the left to explore different features of the app.")
#     # Add any other content for the home page here
# 
# def article_text_viewer_page():
#     st.header("view article text and classify rhetoric")
#     st.write("Enter the URL of a news article to view its extracted text and classify its rhetoric.")
# 
#     url = st.text_input("Enter the URL of a news article:")
# 
#     if url:
#         with st.spinner("Fetching article text..."):
#             article_data = fetch_article_text(url)
# 
#         if "error" in article_data:
#             st.error(article_data["error"])
#         else:
#             st.subheader("Article Text:")
#             article_text = article_data["text"]
#             st.text_area("Article Content", article_text, height=500)
# 
#             st.subheader("Zero-Shot Classification")
#             candidate_labels_input = st.text_input("Enter candidate labels (comma-separated):", "politics, technology, sports, entertainment")
#             candidate_labels = [label.strip() for label in candidate_labels_input.split(",")]
# 
#             if st.button("Classify Rhetoric"):
#                 if article_text and candidate_labels:
#                     with st.spinner("Classifying text..."):
#                         classification_result = classify_text_zero_shot(article_text, candidate_labels)
# 
#                     if "error" in classification_result:
#                         st.error(classification_result["error"])
#                     else:
#                         st.subheader("Classification Results:")
#                         # Display results - you might want to format this better
#                         st.write(classification_result)
#                 else:
#                     st.warning("Please fetch an article and enter candidate labels.")
# 
# 
# def popular_rhetoric_timeline_page():
#     st.header("the story behind the story")
#     st.write("Explore the trends of popular rhetoric over time.")
#     st.warning("This feature is not yet implemented.")
#     # Add the timeline visualization here
# 
# def about_page():
#     st.header("The media tells stories. We tell you why.")
#     st.write("Learn more about the NarrAItives project and the team behind it.")
#     # Add information about the project here
# 
# if __name__ == "__main__":
#     main()

"""# Task
Integrate the provided Hugging Face Inference API code for zero-shot text classification into the Streamlit application code in "app.py", ensuring the API token is correctly accessed as a secret named `HF_API_TOKEN`.

## Modify `app.py` to use the inference api

### Subtask:
Update the `classify_text_zero_shot` function in `app.py` to use the provided API code for classification instead of the `transformers` pipeline.

**Reasoning**:
The subtask is to update the `classify_text_zero_shot` function to use the Hugging Face Inference API. This involves modifying the existing function to construct the API request, send it using `requests`, and process the response. I will also need to import the `requests` library.
"""

# Commented out IPython magic to ensure Python compatibility.
# %%writefile app.py
# 
# import streamlit as st
# import os
# from newspaper import Article
# import matplotlib.pyplot as plt
# import pandas as pd
# import requests # Import the requests library
# 
# # Load Hugging Face zero-shot classification model (This will be replaced by API call)
# # @st.cache_resource
# # def load_model():
# #     return pipeline("zero-shot-classification", model="facebook/bart-large-mnli")
# 
# # classifier = load_model()
# 
# # Function to fetch article text (remains the same)
# def fetch_article_text(url):
#     """Fetches article and returns the text."""
#     try:
#         article = Article(url)
#         article.download()
#         article.parse()
#         text = article.text.strip()
#         return {"text": text}
#     except Exception as e:
#         return {"error": f"Error fetching article: {e}"}
# 
# def classify_text_zero_shot(text, candidate_labels):
#     """Classifies text using zero-shot classification via Hugging Face Inference API."""
#     hf_api_token = os.environ.get("HF_API_TOKEN")
#     if not hf_api_token:
#         return {"error": "Hugging Face API token not found. Please set the HF_API_TOKEN environment variable."}
# 
#     API_URL = "https://api-inference.huggingface.co/models/facebook/bart-large-mnli"
#     headers = {"Authorization": f"Bearer {hf_api_token}"}
# 
#     payload = {
#         "inputs": text,
#         "parameters": {"candidate_labels": candidate_labels},
#     }
# 
#     try:
#         response = requests.post(API_URL, headers=headers, json=payload)
#         response.raise_for_status() # Raise an exception for bad status codes
#         return response.json()
#     except requests.exceptions.RequestException as e:
#         return {"error": f"Error during API classification: {e}"}
# 
# 
# def main():
#     st.sidebar.title("Navigation")
#     page = st.sidebar.radio("Go to", ["Home", "Article Text Viewer", "Popular Rhetoric Timeline", "About"])
# 
#     st.title("NarrAItives")
# 
#     if page == "Home":
#         home_page()
#     elif page == "Article Text Viewer":
#         article_text_viewer_page()
#     elif page == "Popular Rhetoric Timeline":
#         popular_rhetoric_timeline_page()
#     elif page == "About":
#         about_page()
# 
# def home_page():
#     st.header("uncover the patterns shaping your world")
#     st.write("Welcome to NarrAItives! This application helps you analyze news articles.")
#     st.write("Now you can use the 'Article Text Viewer' to fetch article text and perform zero-shot classification.")
#     st.write("Use the navigation on the left to explore different features of the app.")
#     # Add any other content for the home page here
# 
# def article_text_viewer_page():
#     st.header("view article text and classify rhetoric")
#     st.write("Enter the URL of a news article to view its extracted text and classify its rhetoric.")
# 
#     url = st.text_input("Enter the URL of a news article:")
# 
#     if url:
#         with st.spinner("Fetching article text..."):
#             article_data = fetch_article_text(url)
# 
#         if "error" in article_data:
#             st.error(article_data["error"])
#         else:
#             st.subheader("Article Text:")
#             article_text = article_data["text"]
#             st.text_area("Article Content", article_text, height=500)
# 
#             st.subheader("Zero-Shot Classification")
#             candidate_labels_input = st.text_input("Enter candidate labels (comma-separated):", "politics, technology, sports, entertainment")
#             candidate_labels = [label.strip() for label in candidate_labels_input.split(",")]
# 
#             if st.button("Classify Rhetoric"):
#                 if article_text and candidate_labels:
#                     with st.spinner("Classifying text..."):
#                         classification_result = classify_text_zero_shot(article_text, candidate_labels)
# 
#                     if "error" in classification_result:
#                         st.error(classification_result["error"])
#                     else:
#                         st.subheader("Classification Results:")
#                         # Display results - you might want to format this better
#                         st.write(classification_result)
#                 else:
#                     st.warning("Please fetch an article and enter candidate labels.")
# 
# 
# def popular_rhetoric_timeline_page():
#     st.header("the story behind the story")
#     st.write("Explore the trends of popular rhetoric over time.")
#     st.warning("This feature is not yet implemented.")
#     # Add the timeline visualization here
# 
# def about_page():
#     st.header("The media tells stories. We tell you why.")
#     st.write("Learn more about the NarrAItives project and the team behind it.")
#     # Add information about the project here
# 
# if __name__ == "__main__":
#     main()

"""## Update `load model` function

### Subtask:
Modify the `load_model` function or remove it if it's no longer needed after switching to the API.

**Reasoning**:
Based on the previous step, the `load_model` function and the `classifier` variable are no longer used as the classification is now handled by the API call in `classify_text_zero_shot`. Therefore, these can be removed to clean up the code.
"""

# Commented out IPython magic to ensure Python compatibility.
# %%writefile app.py
# 
# import streamlit as st
# import os
# from newspaper import Article
# import matplotlib.pyplot as plt
# import pandas as pd
# import requests # Import the requests library
# 
# # Load Hugging Face zero-shot classification model (This will be replaced by API call)
# # @st.cache_resource
# # def load_model():
# #     return pipeline("zero-shot-classification", model="facebook/bart-large-mnli")
# 
# # classifier = load_model()
# 
# # Function to fetch article text (remains the same)
# def fetch_article_text(url):
#     """Fetches article and returns the text."""
#     try:
#         article = Article(url)
#         article.download()
#         article.parse()
#         text = article.text.strip()
#         return {"text": text}
#     except Exception as e:
#         return {"error": f"Error fetching article: {e}"}
# 
# def classify_text_zero_shot(text, candidate_labels):
#     """Classifies text using zero-shot classification via Hugging Face Inference API."""
#     hf_api_token = os.environ.get("HF_API_TOKEN")
#     if not hf_api_token:
#         return {"error": "Hugging Face API token not found. Please set the HF_API_TOKEN environment variable."}
# 
#     API_URL = "https://api-inference.huggingface.co/models/facebook/bart-large-mnli"
#     headers = {"Authorization": f"Bearer {hf_api_token}"}
# 
#     payload = {
#         "inputs": text,
#         "parameters": {"candidate_labels": candidate_labels},
#     }
# 
#     try:
#         response = requests.post(API_URL, headers=headers, json=payload)
#         response.raise_for_status() # Raise an exception for bad status codes
#         return response.json()
#     except requests.exceptions.RequestException as e:
#         return {"error": f"Error during API classification: {e}"}
# 
# 
# def main():
#     st.sidebar.title("Navigation")
#     page = st.sidebar.radio("Go to", ["Home", "Article Text Viewer", "Popular Rhetoric Timeline", "About"])
# 
#     st.title("NarrAItives")
# 
#     if page == "Home":
#         home_page()
#     elif page == "Article Text Viewer":
#         article_text_viewer_page()
#     elif page == "Popular Rhetoric Timeline":
#         popular_rhetoric_timeline_page()
#     elif page == "About":
#         about_page()
# 
# def home_page():
#     st.header("uncover the patterns shaping your world")
#     st.write("Welcome to NarrAItives! This application helps you analyze news articles.")
#     st.write("Now you can use the 'Article Text Viewer' to fetch article text and perform zero-shot classification.")
#     st.write("Use the navigation on the left to explore different features of the app.")
#     # Add any other content for the home page here
# 
# def article_text_viewer_page():
#     st.header("view article text and classify rhetoric")
#     st.write("Enter the URL of a news article to view its extracted text and classify its rhetoric.")
# 
#     url = st.text_input("Enter the URL of a news article:")
# 
#     if url:
#         with st.spinner("Fetching article text..."):
#             article_data = fetch_article_text(url)
# 
#         if "error" in article_data:
#             st.error(article_data["error"])
#         else:
#             st.subheader("Article Text:")
#             article_text = article_data["text"]
#             st.text_area("Article Content", article_text, height=500)
# 
#             st.subheader("Zero-Shot Classification")
#             candidate_labels_input = st.text_input("Enter candidate labels (comma-separated):", "politics, technology, sports, entertainment")
#             candidate_labels = [label.strip() for label in candidate_labels_input.split(",")]
# 
#             if st.button("Classify Rhetoric"):
#                 if article_text and candidate_labels:
#                     with st.spinner("Classifying text..."):
#                         classification_result = classify_text_zero_shot(article_text, candidate_labels)
# 
#                     if "error" in classification_result:
#                         st.error(classification_result["error"])
#                     else:
#                         st.subheader("Classification Results:")
#                         # Display results - you might want to format this better
#                         st.write(classification_result)
#                 else:
#                     st.warning("Please fetch an article and enter candidate labels.")
# 
# 
# def popular_rhetoric_timeline_page():
#     st.header("the story behind the story")
#     st.write("Explore the trends of popular rhetoric over time.")
#     st.warning("This feature is not yet implemented.")
#     # Add the timeline visualization here
# 
# def about_page():
#     st.header("The media tells stories. We tell you why.")
#     st.write("Learn more about the NarrAItives project and the team behind it.")
#     # Add information about the project here
# 
# if __name__ == "__main__":
#     main()

"""## Adjust api token usage

### Subtask:
Ensure the code correctly accesses the `HF_API_TOKEN` secret for the API call.

**Reasoning**:
Review the `classify_text_zero_shot` function to ensure it correctly accesses the `HF_API_TOKEN` environment variable and includes it in the API request headers, also checking for proper handling of missing tokens.
"""

# Verify the implementation in classify_text_zero_shot
with open('app.py', 'r') as f:
    app_code = f.read()

print(app_code)

"""## Test the updated app

### Subtask:
Run the Streamlit app locally to ensure the classification works correctly using the API.

**Reasoning**:
The previous steps have prepared the `app.py` file for execution. Now, I need to run the Streamlit application locally to test the API integration and classification functionality as per the subtask instructions.
"""

!streamlit run app.py

"""**Reasoning**:
The previous attempt to run Streamlit failed because the `streamlit` command was not found. Although I installed the package in the first step, it seems it's not in the system's PATH or accessible directly. I will try running it using `python -m streamlit run app.py` which is a more robust way to execute installed Python packages.


"""

!python -m streamlit run app.py

"""**Reasoning**:
The previous attempt to run Streamlit using `python -m` also failed, indicating that the `streamlit` module is not found. This suggests that the installation in the first step might not have been successful or the environment setup is not as expected. I will try installing streamlit again explicitly with the `--break-system-packages` flag, which is sometimes necessary in environments like this to avoid conflicts, and then attempt to run the app again.


"""

# Commented out IPython magic to ensure Python compatibility.
# %pip install streamlit --break-system-packages
!python -m streamlit run app.py